2021-05-27 10:30:52 - __main__ - INFO: ===== import configuration =====
2021-05-27 10:30:52 - root - INFO: Config:
2021-05-27 10:30:52 - root - INFO: [Dataset]
2021-05-27 10:30:52 - root - INFO: Dataset_path = data/traditional_ch/msra
2021-05-27 10:30:52 - root - INFO: is_cls_flag = True
2021-05-27 10:30:52 - root - INFO: align_for_token_maxlen = False
2021-05-27 10:30:52 - root - INFO: cls_padding_idx = 0
2021-05-27 10:30:52 - root - INFO: token_padding_idx = 0
2021-05-27 10:30:52 - root - INFO: label_padding_idx = -1
2021-05-27 10:30:52 - root - INFO: token_max_len = 128
2021-05-27 10:30:52 - root - INFO: sample_seed = 207
2021-05-27 10:30:52 - root - INFO: 
2021-05-27 10:30:52 - root - INFO: [model]
2021-05-27 10:30:52 - root - INFO: mode = training
2021-05-27 10:30:52 - root - INFO: num_labels = 7
2021-05-27 10:30:52 - root - INFO: selected_model = NER_For_Bert
2021-05-27 10:30:52 - root - INFO: selected_optimizer = Transformer_Adaw
2021-05-27 10:30:52 - root - INFO: selected_scheduler = cosine_schedule_with_warmup
2021-05-27 10:30:52 - root - INFO: 
2021-05-27 10:30:52 - root - INFO: [Label_mapping]
2021-05-27 10:30:52 - root - INFO: O = 0
2021-05-27 10:30:52 - root - INFO: B-PER = 1
2021-05-27 10:30:52 - root - INFO: I-PER = 2
2021-05-27 10:30:52 - root - INFO: B-ORG = 3
2021-05-27 10:30:52 - root - INFO: I-ORG = 4
2021-05-27 10:30:52 - root - INFO: B-LOC = 5
2021-05-27 10:30:52 - root - INFO: I-LOC = 6
2021-05-27 10:30:52 - root - INFO: 
2021-05-27 10:30:52 - root - INFO: [Label]
2021-05-27 10:30:52 - root - INFO: label_type = PER,ORG,LOC
2021-05-27 10:30:52 - root - INFO: 
2021-05-27 10:30:52 - root - INFO: [TF_model]
2021-05-27 10:30:52 - root - INFO: TF_Bert_pretrained_model = pretrained_bert_models/tensorflow/Bert_chinese_L-12_H-768_A-12/
2021-05-27 10:30:52 - root - INFO: TF_Bert_config = pretrained_bert_models/tensorflow/Bert_chinese_L-12_H-768_A-12/bert_config.json
2021-05-27 10:30:52 - root - INFO: TF_Bert_checkpoint = pretrained_bert_models/tensorflow/Bert_chinese_L-12_H-768_A-12/bert_model.ckpt
2021-05-27 10:30:52 - root - INFO: TF_Bert_vocab = pretrained_bert_models/tensorflow/Bert_chinese_L-12_H-768_A-12/vocab.txt
2021-05-27 10:30:52 - root - INFO: 
2021-05-27 10:30:52 - root - INFO: [pytorch_model]
2021-05-27 10:30:52 - root - INFO: pytorch_Bert_pretrained_model = pretrained_bert_models/pytorch/Bert_chinese_L-12_H-768_A-12/
2021-05-27 10:30:52 - root - INFO: pytorch_Bert_vocab = pretrained_bert_models/pytorch/Bert_chinese_L-12_H-768_A-12/vocab.txt
2021-05-27 10:30:52 - root - INFO: pytorch_Bert_model = ./experiments/checkpoint_2021-05-25_23_33_10/
2021-05-27 10:30:52 - root - INFO: 
2021-05-27 10:30:52 - root - INFO: [env]
2021-05-27 10:30:52 - root - INFO: devive = cuda
2021-05-27 10:30:52 - root - INFO: 
2021-05-27 10:30:52 - root - INFO: [hyperparameter]
2021-05-27 10:30:52 - root - INFO: full_fine_tuning = True
2021-05-27 10:30:52 - root - INFO: batch_size = 16
2021-05-27 10:30:52 - root - INFO: epoch_num = 50
2021-05-27 10:30:52 - root - INFO: learning_rate = 3e-5
2021-05-27 10:30:52 - root - INFO: weight_decay = 0.01
2021-05-27 10:30:52 - root - INFO: clip_grad = 5
2021-05-27 10:30:52 - root - INFO: patience_num = 5
2021-05-27 10:30:52 - root - INFO: patience_value = 0.01
2021-05-27 10:30:52 - root - INFO: 
2021-05-27 10:30:52 - root - INFO: [training_setting]
2021-05-27 10:30:52 - root - INFO: saving_model_path = ./experiments/
2021-05-27 10:30:52 - root - INFO: 
2021-05-27 10:30:52 - __main__ - INFO: ===== import data =====
2021-05-27 10:31:16 - __main__ - INFO: ===== getting model =====
2021-05-27 10:31:21 - __main__ - INFO: ===== Starting Training =====
2021-05-27 10:31:21 - __main__ - INFO: ===== Epoch 1=====
2021-05-27 11:06:51 - __main__ - INFO: Epoch: 1, train loss: 335.10649354480563
2021-05-27 11:07:56 - __main__ - INFO: evaluate: {'full': 0.404, 'label_score': {'PER': 0.7386666666666667, 'ORG': 0.6913333333333334, 'LOC': 0.549}}
2021-05-27 11:07:56 - __main__ - INFO: best_eval_metric = 0.404;current_num_patience = 0
2021-05-27 11:07:56 - __main__ - INFO: ===== Epoch 2=====
2021-05-27 11:42:25 - __main__ - INFO: Epoch: 2, train loss: 136.79549534679595
2021-05-27 11:43:30 - __main__ - INFO: evaluate: {'full': 0.55, 'label_score': {'PER': 0.8473333333333334, 'ORG': 0.7736666666666666, 'LOC': 0.7133333333333335}}
2021-05-27 11:43:30 - __main__ - INFO: ***** Saving model *****
2021-05-27 11:43:33 - __main__ - INFO: best_eval_metric = 0.55;current_num_patience = 0
2021-05-27 11:43:33 - __main__ - INFO: ===== Epoch 3=====
2021-05-27 12:18:02 - __main__ - INFO: Epoch: 3, train loss: 83.76564450509207
2021-05-27 12:19:06 - __main__ - INFO: evaluate: {'full': 0.635, 'label_score': {'PER': 0.8923333333333333, 'ORG': 0.8146666666666665, 'LOC': 0.779}}
2021-05-27 12:19:06 - __main__ - INFO: ***** Saving model *****
2021-05-27 12:19:08 - __main__ - INFO: best_eval_metric = 0.635;current_num_patience = 0
2021-05-27 12:19:08 - __main__ - INFO: ===== Epoch 4=====
2021-05-27 12:53:42 - __main__ - INFO: Epoch: 4, train loss: 58.42759747314453
2021-05-27 12:54:47 - __main__ - INFO: evaluate: {'full': 0.7036666666666667, 'label_score': {'PER': 0.9143333333333333, 'ORG': 0.8636666666666667, 'LOC': 0.8243333333333334}}
2021-05-27 12:54:47 - __main__ - INFO: ***** Saving model *****
2021-05-27 12:54:49 - __main__ - INFO: best_eval_metric = 0.7036666666666667;current_num_patience = 0
2021-05-27 12:54:49 - __main__ - INFO: ===== Epoch 5=====
2021-05-27 13:29:15 - __main__ - INFO: Epoch: 5, train loss: 41.842664427257716
2021-05-27 13:30:19 - __main__ - INFO: evaluate: {'full': 0.7250000000000001, 'label_score': {'PER': 0.9223333333333333, 'ORG': 0.8686666666666667, 'LOC': 0.839}}
2021-05-27 13:30:19 - __main__ - INFO: ***** Saving model *****
2021-05-27 13:30:22 - __main__ - INFO: best_eval_metric = 0.7250000000000001;current_num_patience = 0
2021-05-27 13:30:22 - __main__ - INFO: ===== Epoch 6=====
2021-05-27 14:04:57 - __main__ - INFO: Epoch: 6, train loss: 29.92323702857608
2021-05-27 14:06:02 - __main__ - INFO: evaluate: {'full': 0.745, 'label_score': {'PER': 0.9123333333333333, 'ORG': 0.8693333333333333, 'LOC': 0.8673333333333333}}
2021-05-27 14:06:02 - __main__ - INFO: ***** Saving model *****
2021-05-27 14:06:04 - __main__ - INFO: best_eval_metric = 0.745;current_num_patience = 0
2021-05-27 14:06:04 - __main__ - INFO: ===== Epoch 7=====
2021-05-27 14:40:34 - __main__ - INFO: Epoch: 7, train loss: 21.686504114060174
2021-05-27 14:41:38 - __main__ - INFO: evaluate: {'full': 0.776, 'label_score': {'PER': 0.936, 'ORG': 0.8933333333333333, 'LOC': 0.8769999999999999}}
2021-05-27 14:41:38 - __main__ - INFO: ***** Saving model *****
2021-05-27 14:41:40 - __main__ - INFO: best_eval_metric = 0.776;current_num_patience = 0
2021-05-27 14:41:40 - __main__ - INFO: ===== Epoch 8=====
2021-05-27 15:16:05 - __main__ - INFO: Epoch: 8, train loss: 16.004355207170757
2021-05-27 15:17:09 - __main__ - INFO: evaluate: {'full': 0.793, 'label_score': {'PER': 0.9446666666666667, 'ORG': 0.9086666666666666, 'LOC': 0.8803333333333333}}
2021-05-27 15:17:09 - __main__ - INFO: ***** Saving model *****
2021-05-27 15:17:12 - __main__ - INFO: best_eval_metric = 0.793;current_num_patience = 0
2021-05-27 15:17:12 - __main__ - INFO: ===== Epoch 9=====
2021-05-27 15:51:39 - __main__ - INFO: Epoch: 9, train loss: 11.812684900192988
2021-05-27 15:52:43 - __main__ - INFO: evaluate: {'full': 0.7903333333333333, 'label_score': {'PER': 0.9256666666666666, 'ORG': 0.912, 'LOC': 0.8903333333333333}}
2021-05-27 15:52:43 - __main__ - INFO: best_eval_metric = 0.793;current_num_patience = 1
2021-05-27 15:52:43 - __main__ - INFO: ===== Epoch 10=====
2021-05-27 16:27:17 - __main__ - INFO: Epoch: 10, train loss: 8.983210455031623
2021-05-27 16:28:22 - __main__ - INFO: evaluate: {'full': 0.805, 'label_score': {'PER': 0.945, 'ORG': 0.904, 'LOC': 0.8953333333333333}}
2021-05-27 16:28:22 - __main__ - INFO: ***** Saving model *****
2021-05-27 16:28:24 - __main__ - INFO: best_eval_metric = 0.805;current_num_patience = 0
2021-05-27 16:28:24 - __main__ - INFO: ===== Epoch 11=====
2021-05-27 17:02:58 - __main__ - INFO: Epoch: 11, train loss: 7.099935273670015
2021-05-27 17:04:02 - __main__ - INFO: evaluate: {'full': 0.824, 'label_score': {'PER': 0.942, 'ORG': 0.918, 'LOC': 0.905}}
2021-05-27 17:04:02 - __main__ - INFO: ***** Saving model *****
2021-05-27 17:04:05 - __main__ - INFO: best_eval_metric = 0.824;current_num_patience = 0
2021-05-27 17:04:05 - __main__ - INFO: ===== Epoch 12=====
2021-05-27 17:38:44 - __main__ - INFO: Epoch: 12, train loss: 5.675945925757999
2021-05-27 17:39:49 - __main__ - INFO: evaluate: {'full': 0.8143333333333334, 'label_score': {'PER': 0.941, 'ORG': 0.9133333333333333, 'LOC': 0.9026666666666666}}
2021-05-27 17:39:49 - __main__ - INFO: best_eval_metric = 0.824;current_num_patience = 1
2021-05-27 17:39:49 - __main__ - INFO: ===== Epoch 13=====
2021-05-27 18:14:21 - __main__ - INFO: Epoch: 13, train loss: 4.602275444394066
2021-05-27 18:15:25 - __main__ - INFO: evaluate: {'full': 0.826, 'label_score': {'PER': 0.9466666666666667, 'ORG': 0.9206666666666665, 'LOC': 0.905}}
2021-05-27 18:15:25 - __main__ - INFO: ***** Saving model *****
2021-05-27 18:15:27 - __main__ - INFO: best_eval_metric = 0.826;current_num_patience = 0
2021-05-27 18:15:27 - __main__ - INFO: ===== Epoch 14=====
2021-05-27 18:50:04 - __main__ - INFO: Epoch: 14, train loss: 3.864832255170459
2021-05-27 18:51:08 - __main__ - INFO: evaluate: {'full': 0.8226666666666667, 'label_score': {'PER': 0.9483333333333334, 'ORG': 0.9146666666666666, 'LOC': 0.9006666666666666}}
2021-05-27 18:51:08 - __main__ - INFO: best_eval_metric = 0.826;current_num_patience = 1
2021-05-27 18:51:08 - __main__ - INFO: ===== Epoch 15=====
2021-05-27 19:25:41 - __main__ - INFO: Epoch: 15, train loss: 3.311455923670814
2021-05-27 19:26:45 - __main__ - INFO: evaluate: {'full': 0.8233333333333334, 'label_score': {'PER': 0.9446666666666667, 'ORG': 0.9226666666666666, 'LOC': 0.9016666666666667}}
2021-05-27 19:26:45 - __main__ - INFO: best_eval_metric = 0.826;current_num_patience = 2
2021-05-27 19:26:45 - __main__ - INFO: ===== Epoch 16=====
2021-05-27 20:01:01 - __main__ - INFO: Epoch: 16, train loss: 3.160290746439071
2021-05-27 20:02:03 - __main__ - INFO: evaluate: {'full': 0.8236666666666665, 'label_score': {'PER': 0.944, 'ORG': 0.9216666666666666, 'LOC': 0.9043333333333333}}
2021-05-27 20:02:03 - __main__ - INFO: best_eval_metric = 0.826;current_num_patience = 3
2021-05-27 20:02:03 - __main__ - INFO: ===== Epoch 17=====
2021-05-27 20:34:33 - __main__ - INFO: Epoch: 17, train loss: 2.8136994047619046
2021-05-27 20:35:33 - __main__ - INFO: evaluate: {'full': 0.8183333333333332, 'label_score': {'PER': 0.9466666666666667, 'ORG': 0.914, 'LOC': 0.9}}
2021-05-27 20:35:33 - __main__ - INFO: best_eval_metric = 0.826;current_num_patience = 4
2021-05-27 20:35:33 - __main__ - INFO: ===== Epoch 18=====
2021-05-27 21:07:59 - __main__ - INFO: Epoch: 18, train loss: 2.2977919456845237
2021-05-27 21:09:01 - __main__ - INFO: evaluate: {'full': 0.825, 'label_score': {'PER': 0.9433333333333332, 'ORG': 0.9209999999999999, 'LOC': 0.9056666666666666}}
2021-05-27 21:09:01 - __main__ - INFO: best_eval_metric = 0.826;current_num_patience = 5
2021-05-27 21:09:01 - __main__ - INFO: Best Epoch: 18 ; Best train loss: 2.2977919456845237 ; Best val f1
2021-05-27 21:09:01 - __main__ - INFO: Training Finished!
